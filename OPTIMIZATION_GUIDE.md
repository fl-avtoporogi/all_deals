# Руководство по оптимизации refresh_deals_NEW.php

## Проблема

Текущий `refresh_deals.php` обрабатывает 50000 сделок за **~9 часов** (~92 сделки/мин).

### Причины медленной работы:

1. **HTTP-запросы**: Для каждой сделки делается HTTP-запрос к `index.php`
2. **Множественные API запросы**: Для каждой сделки:
   - 1 запрос `crm.deal.get`
   - 1 запрос `crm.deal.productrows.get`
   - N запросов `catalog.product.get` (для каждого товара)
   - 3-5 запросов для справочников (стадии, пользователи, отделы)
   - **Итого: 10-50 API запросов на одну сделку!**
3. **Единичные INSERT**: Каждая сделка записывается отдельным запросом
4. **Без кэширования**: Справочники загружаются заново для каждой сделки

## Решение: refresh_deals_NEW.php

### Ключевые оптимизации:

#### 1. Batch-запросы API (x10-20 ускорение)
```php
// СТАРЫЙ ПОДХОД (index.php):
// Для каждой сделки: 10-50 отдельных API запросов
for each deal {
    crm.deal.get
    crm.deal.productrows.get
    for each product {
        catalog.product.get  // ← N запросов!
    }
    crm.status.list
    user.get
    department.get
}

// НОВЫЙ ПОДХОД (refresh_deals_NEW.php):
// Для 50 сделок одновременно: 2-3 batch-запроса
batch_1 = [
    'deal_1' => crm.deal.get(1),
    'deal_2' => crm.deal.get(2),
    ...
    'deal_50' => crm.deal.get(50),
    'products_1' => crm.deal.productrows.get(1),
    ...
]

batch_2 = [
    'product_1' => catalog.product.get(1),
    'product_2' => catalog.product.get(2),
    ...
    'product_50' => catalog.product.get(50)
]
```

**Экономия**: Вместо 500-2500 запросов на 50 сделок → всего 2-3 batch-запроса!

#### 2. Кэширование справочников (x5-10 ускорение)
```php
// Загружаются ОДИН РАЗ в начале работы:
- Стадии сделок (все воронки)
- Категории сделок
- Пользователи
- Отделы
- Коды бонусов
- Пользовательские поля

// Кэш сохраняется на диск (TTL = 1 час)
// При повторном запуске - мгновенная загрузка
```

**Экономия**: Вместо 150,000+ запросов для справочников → 1 раз в час!

#### 3. Bulk INSERT (x20-50 ускорение записи в БД)
```php
// СТАРЫЙ ПОДХОД:
for each deal {
    INSERT INTO all_deals VALUES (...)  // 1 запрос = 1 сделка
}
// 50000 сделок = 50000 SQL-запросов

// НОВЫЙ ПОДХОД:
INSERT INTO all_deals VALUES
    (deal_1),
    (deal_2),
    ...
    (deal_100)  // 1 запрос = 100 сделок
// 50000 сделок = 500 SQL-запросов
```

**Экономия**: Вместо 50,000 запросов → 500 запросов (x100 меньше)!

#### 4. Прямая обработка (x2-3 ускорение)
```php
// СТАРЫЙ ПОДХОД:
PHP script → HTTP request → index.php → API → БД
// Overhead: сетевые задержки, инициализация PHP на каждый запрос

// НОВЫЙ ПОДХОД:
PHP script → API → БД
// Прямая обработка без промежуточных слоев
```

#### 5. Умное кэширование товаров
```php
// Собираем все уникальные ID товаров из пакета сделок
// Делаем ОДИН batch-запрос для всех товаров
// Товар запрашивается только 1 раз, даже если он в 10 сделках
```

## Сравнение производительности

| Метрика | refresh_deals.php | refresh_deals_NEW.php | Ускорение |
|---------|-------------------|----------------------|-----------|
| **API запросов на сделку** | 10-50 | 0.02-0.05 | **x200-2500** |
| **Сделок в пакете** | 10-20 (параллельно) | 50 (batch) | x2.5-5 |
| **SQL запросов** | 1 на сделку | 1 на 100 сделок | **x100** |
| **Справочники** | Каждый раз | 1 раз (кэш) | **x∞** |
| **Скорость** | ~92 сделки/мин | ~300-1000 сделки/мин | **x3-10** |
| **Время для 50k** | ~9 часов | ~1-2 часа | **x4.5-9** |

## Использование

### 1. Тестовый запуск (рекомендуется сначала!)
```bash
# Обработать только 100 сделок для теста
php refresh_deals_NEW.php limit 100
```

**Проверьте результаты в БД перед полным запуском!**

### 2. Обычный запуск
```bash
php refresh_deals_NEW.php
```

### 3. Сброс прогресса
```bash
php refresh_deals_NEW.php reset
```

### 4. Продолжение после прерывания
Просто запустите снова:
```bash
php refresh_deals_NEW.php
```
Скрипт автоматически продолжит с последней обработанной сделки.

## Мониторинг прогресса

Скрипт выводит детальную статистику:
```
[5000/50000] 10.0% | Пакет: 50 сделок за 5.2s (576/мин) | Всего: 612.3/мин | ETA: 01:13:24
```

Расшифровка:
- `5000/50000` - обработано/всего сделок
- `10.0%` - процент выполнения
- `Пакет: 50 сделок за 5.2s` - текущий пакет
- `576/мин` - скорость текущего пакета
- `612.3/мин` - средняя скорость за всё время
- `ETA: 01:13:24` - оставшееся время

## Файлы прогресса и кэша

### Прогресс
- Файл: `refresh_progress_new.json`
- Содержит: последний обработанный ID, счетчики
- Автоматически удаляется после завершения

### Кэш
- Директория: `cache/`
- Файлы: MD5-хеши ключей кэша
- TTL: 1 час
- Очищается командой `reset`

## Системные требования

```php
memory_limit = 1024M  // Увеличен для обработки больших пакетов
max_execution_time = 0 // Без ограничений
```

## Безопасность

1. **Транзакционность**: `ON DUPLICATE KEY UPDATE` - безопасное обновление
2. **Prepared statements**: Защита от SQL-injection
3. **Обработка ошибок**: Graceful degradation при ошибках API
4. **Сохранение прогресса**: Можно прервать и продолжить в любой момент

## Технические детали

### Константы (можно настроить)
```php
define('BATCH_SIZE', 50);        // Сделок в batch-запросе (макс 50 для API B24)
define('DB_BULK_SIZE', 100);     // Записей в bulk INSERT
define('CACHE_TTL', 3600);       // TTL кэша в секундах
```

### Ограничения API Битрикс24
- Максимум 50 команд в одном batch-запросе
- Лимит: 2 запроса в секунду (скрипт автоматически укладывается)

## Устранение проблем

### "Ошибка batch-запроса"
- Проверьте доступность API Битрикс24
- Проверьте настройки CRest

### "Память исчерпана"
```bash
php -d memory_limit=2048M refresh_deals_NEW.php
```

### "Слишком медленно"
1. Проверьте скорость интернета
2. Уменьшите `BATCH_SIZE` до 25-30
3. Проверьте нагрузку на сервер

### Пустые значения в БД
- Проверьте, что справочники загружены (смотрите вывод в начале)
- Очистите кэш: `php refresh_deals_NEW.php reset`

## Рекомендации

### Для максимальной производительности:
1. **Запускайте на сервере** (не на локальной машине)
2. **Хороший интернет** (низкий ping до Битрикс24)
3. **SSD диск** для быстрого кэша
4. **Ночное время** когда API Битрикс24 менее загружен

### Для безопасности:
1. **Сначала тестовый запуск** с `limit 100`
2. **Проверьте результаты** в БД
3. **Сделайте backup БД** перед полным запуском

## Математика оптимизации

### Старый подход (refresh_deals.php):
```
50,000 сделок × 20 API запросов × 0.5 сек = 500,000 сек = 138 часов (!!)
Благодаря параллельности (10-20 потоков): 138ч / 15 = 9.2 часа
```

### Новый подход (refresh_deals_NEW.php):
```
Справочники: 7 batch-запросов × 1 сек = 7 сек (1 раз!)
50,000 сделок / 50 в batch = 1,000 batch-запросов
1,000 batch × 5 сек = 5,000 сек = 1.4 часа

Итого: ~1.5 часа (с учетом товаров)
```

## Заключение

**refresh_deals_NEW.php** использует современные подходы оптимизации:
- Batch-обработка
- Интеллектуальное кэширование
- Массовые операции с БД
- Минимизация сетевых запросов

**Результат**: Обработка 50,000 сделок за **1-2 часа** вместо **9 часов** (ускорение в **4.5-9 раз**).
